<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>02-05. ì›¹ë°ì´í„° ìˆ˜ì§‘</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    body { 
      font-family: 'Segoe UI', 'Malgun Gothic', system-ui, -apple-system, BlinkMacSystemFont, sans-serif; 
      line-height: 1.6; 
      padding: 20px 15px; 
      max-width: 900px; 
      margin: 0 auto; 
      background: #000000;
      color: #e0e0e0;
    }
    
    .container {
      background: #1a1a1a;
      border-radius: 15px;
      box-shadow: 0 10px 40px rgba(0,0,0,0.5);
      padding: 30px 25px;
      border: 1px solid #333;
    }
    
    h1, h2, h3 { 
      color: #ffffff; 
    }
    
    h1 { 
      border-bottom: 4px solid #888; 
      padding-bottom: 10px; 
      margin-bottom: 20px;
      font-size: 2em;
      text-align: center;
      color: #ffffff;
    }
    
    h2 {
      color: #ffffff;
      font-size: 1.6em;
      margin-top: 25px;
      margin-bottom: 15px;
      padding-left: 15px;
      border-left: 5px solid #888;
    }
    
    h3 {
      color: #ffffff;
      font-size: 1.3em;
      margin-top: 20px;
      margin-bottom: 10px;
    }
    
    code { 
      background: #2a2a2a; 
      color: #d0d0d0;
      padding: 3px 8px; 
      border-radius: 5px; 
      font-family: "Consolas", "Menlo", "Courier New", monospace; 
      font-size: 0.95em;
      font-weight: bold;
      border: 1px solid #444;
    }
    
    pre { 
      background: #1e1e1e; 
      color: #d4d4d4; 
      padding: 15px; 
      border-radius: 8px; 
      overflow-x: auto; 
      font-size: 14px;
      line-height: 1.6;
      box-shadow: 0 2px 8px rgba(0,0,0,0.5);
      margin: 10px 0;
      border: 1px solid #333;
    }
    
    pre code {
      background: transparent;
      border: none;
      padding: 0;
      color: #d4d4d4;
    }
    
    .box { 
      background: #2a2a2a; 
      padding: 15px; 
      border-radius: 10px; 
      margin-bottom: 15px; 
      box-shadow: 0 2px 8px rgba(0,0,0,0.3);
      border-left: 4px solid #888;
      border: 1px solid #444;
    }
    
    .section-box {
      background: #2a2a2a;
      padding: 15px;
      border-radius: 10px;
      margin: 15px 0;
      border-left: 4px solid #888;
      border: 1px solid #444;
    }
    
    .tip { 
      font-size: 0.95em; 
      color: #d0d0d0;
      margin-top: 10px;
      padding: 10px;
      background: #2a2a2a;
      border-left: 4px solid #888;
      border-radius: 5px;
      border: 1px solid #444;
    }
    
    .tip strong {
      color: #ffffff;
    }
    
    .warning {
      background: #3a2a1a;
      border-left: 4px solid #ff6b6b;
      color: #ffcccc;
      padding: 10px;
      border-radius: 5px;
      margin: 10px 0;
      border: 1px solid #555;
    }
    
    .summary {
      background: #1a2a2a;
      border-left: 4px solid #888;
      color: #d0d0d0;
      padding: 15px;
      border-radius: 5px;
      margin: 15px 0;
      border: 1px solid #444;
    }
    
    .summary h3 {
      margin-top: 0;
      color: #ffffff;
    }
    
    ol { 
      padding-left: 25px; 
    }
    
    li { 
      margin-bottom: 6px; 
      line-height: 1.6;
    }
    
    ul {
      padding-left: 25px;
    }
    
    p {
      margin-bottom: 10px;
      line-height: 1.8;
    }
    
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 15px 0;
      background: #2a2a2a;
      border-radius: 8px;
      overflow: hidden;
      border: 1px solid #444;
    }
    
    thead {
      background: #1a1a1a;
      color: #ffffff;
      border-bottom: 2px solid #666;
    }
    
    th {
      padding: 12px;
      text-align: left;
      font-weight: 600;
      color: #ffffff;
    }
    
    td {
      padding: 10px 12px;
      border-bottom: 1px solid #444;
      color: #e0e0e0;
    }
    
    tr:hover {
      background: #333;
    }
    
    tr:last-child td {
      border-bottom: none;
    }
    
    .checklist {
      background: #2a2a2a;
      padding: 15px;
      border-radius: 10px;
      margin: 15px 0;
      border: 1px solid #444;
    }
    
    .checklist-item {
      margin: 8px 0;
      padding-left: 25px;
      position: relative;
    }
    
    .checklist-item input[type="checkbox"] {
      position: absolute;
      left: 0;
      margin-top: 3px;
    }
    
    img {
      max-width: 100%;
      height: auto;
      border: 2px solid #666;
      border-radius: 8px;
      margin: 15px 0;
      box-shadow: 0 4px 12px rgba(0,0,0,0.5);
    }
    
    hr {
      border: none;
      border-top: 2px solid #444;
      margin: 25px 0;
    }
    
    a {
      color: #888;
      text-decoration: underline;
    }
    
    a:hover {
      color: #ffffff;
    }
    
    .footer {
      text-align: center;
      color: #888;
      margin-top: 40px;
      padding-top: 20px;
      border-top: 2px solid #444;
      font-size: 0.9em;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>02-05. ì›¹ë°ì´í„° ìˆ˜ì§‘</h1>
    
    <div class="section-box">
    <h2>ğŸ“‹ ëª©ì°¨</h2>
    <ul>
    <li><a href="#1-ì›¹ë°ì´í„°-ìˆ˜ì§‘-ê°œìš”">1. ì›¹ë°ì´í„° ìˆ˜ì§‘ ê°œìš”</a></li>
    <li><a href="#2-requests-ë¼ì´ë¸ŒëŸ¬ë¦¬">2. requests ë¼ì´ë¸ŒëŸ¬ë¦¬</a></li>
    <li><a href="#3-beautifulsoupìœ¼ë¡œ-html-íŒŒì‹±">3. BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±</a></li>
    <li><a href="#4-seleniumìœ¼ë¡œ-ë™ì -ì›¹í˜ì´ì§€-ì²˜ë¦¬">4. Seleniumìœ¼ë¡œ ë™ì  ì›¹í˜ì´ì§€ ì²˜ë¦¬</a></li>
    <li><a href="#5-ë°ì´í„°-ì €ì¥">5. ë°ì´í„° ì €ì¥</a></li>
    <li><a href="#6-ì‹¤ì „-ì˜ˆì œ">6. ì‹¤ì „ ì˜ˆì œ</a></li>
    <li><a href="#7-ì£¼ì˜ì‚¬í•­ê³¼-ëª¨ë²”-ì‚¬ë¡€">7. ì£¼ì˜ì‚¬í•­ê³¼ ëª¨ë²” ì‚¬ë¡€</a></li>
    <li><a href="#8-ìš”ì•½">8. ìš”ì•½</a></li>
    </ul>
    <hr>
    <h2>1. ì›¹ë°ì´í„° ìˆ˜ì§‘ ê°œìš”</h2>
    <h3>1.1 ì›¹ ìŠ¤í¬ë˜í•‘ì´ë€?</h3>
    <p><strong>ì›¹ ìŠ¤í¬ë˜í•‘(Web Scraping)</strong>ì€ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.</p>
    <p><strong>ì£¼ìš” ìš©ë„:</strong></p>
    <ul>
    <li>ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘</li>
    <li>ìƒí’ˆ ê°€ê²© ëª¨ë‹ˆí„°ë§</li>
    <li>ë‚ ì”¨ ì •ë³´ ìˆ˜ì§‘</li>
    <li>ì†Œì…œ ë¯¸ë””ì–´ ë°ì´í„° ë¶„ì„</li>
    <li>ì—°êµ¬ìš© ë°ì´í„° ìˆ˜ì§‘</li>
    </ul>
    <h3>1.2 í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬</h3>
    <pre><code class="language-python"># ì„¤ì¹˜ ëª…ë ¹ì–´
# pip install requests beautifulsoup4 selenium pandas lxml

import requests          # HTTP ìš”ì²­
from bs4 import BeautifulSoup  # HTML íŒŒì‹±
from selenium import webdriver  # ë™ì  ì›¹í˜ì´ì§€ ì²˜ë¦¬
import pandas as pd     # ë°ì´í„° ì²˜ë¦¬
import time             # ëŒ€ê¸° ì‹œê°„</code></pre>
    <div class="warning"><strong>âš ï¸ Warning: ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œ í•´ë‹¹ ì›¹ì‚¬ì´íŠ¸ì˜ ì´ìš©ì•½ê´€ê³¼ robots.txtë¥¼ í™•ì¸í•˜ê³ , ì„œë²„ì— ë¶€í•˜ë¥¼ ì£¼ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.</strong></div>
    <hr>
    <h2>2. requests ë¼ì´ë¸ŒëŸ¬ë¦¬</h2>
    <h3>2.1 ê¸°ë³¸ GET ìš”ì²­</h3>
    <pre><code class="language-python">import requests

# ê¸°ë³¸ ìš”ì²­
response = requests.get("https://www.example.com")

# ìƒíƒœ ì½”ë“œ í™•ì¸
print(response.status_code)  # 200 (ì„±ê³µ)

# ì‘ë‹µ ë‚´ìš©
print(response.text)  # HTML ë‚´ìš©
print(response.content)  # ë°”ì´ë„ˆë¦¬ ë°ì´í„°</code></pre>
    <h3>2.2 í—¤ë” ì„¤ì •</h3>
    <pre><code class="language-python">import requests

# User-Agent ì„¤ì • (ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ê²Œ)
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
}

response = requests.get("https://www.example.com", headers=headers)</code></pre>
    <h3>2.3 íŒŒë¼ë¯¸í„° ì „ë‹¬</h3>
    <pre><code class="language-python">import requests

# URL íŒŒë¼ë¯¸í„°
params = {
    "q": "python",
    "page": 1
}

response = requests.get("https://www.example.com/search", params=params)
print(response.url)  # ì‹¤ì œ ìš”ì²­ URL í™•ì¸</code></pre>
    <h3>2.4 ì—ëŸ¬ ì²˜ë¦¬</h3>
    <pre><code class="language-python">import requests

try:
    response = requests.get("https://www.example.com", timeout=5)
    response.raise_for_status()  # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
    print("ìš”ì²­ ì„±ê³µ")
except requests.exceptions.RequestException as e:
    print(f"ìš”ì²­ ì‹¤íŒ¨: {e}")</code></pre>
    <hr>
    <h2>3. BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±</h2>
    <h3>3.1 ê¸°ë³¸ ì‚¬ìš©ë²•</h3>
    <pre><code class="language-python">import requests
from bs4 import BeautifulSoup

# ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
url = "https://www.example.com"
response = requests.get(url)
html = response.text

# BeautifulSoup ê°ì²´ ìƒì„±
soup = BeautifulSoup(html, "html.parser")

# HTML êµ¬ì¡° í™•ì¸
print(soup.prettify())</code></pre>
    <h3>3.2 íƒœê·¸ ì°¾ê¸°</h3>
    <pre><code class="language-python">from bs4 import BeautifulSoup

html = """
&lt;html&gt;
&lt;body&gt;
    &lt;h1&gt;ì œëª©&lt;/h1&gt;
    &lt;p class="content"&gt;ë‚´ìš© 1&lt;/p&gt;
    &lt;p class="content"&gt;ë‚´ìš© 2&lt;/p&gt;
    &lt;a href="https://example.com"&gt;ë§í¬&lt;/a&gt;
&lt;/body&gt;
&lt;/html&gt;
"""

soup = BeautifulSoup(html, "html.parser")

# íƒœê·¸ë¡œ ì°¾ê¸°
title = soup.find("h1")
print(title.text)  # ì œëª©

# ëª¨ë“  íƒœê·¸ ì°¾ê¸°
paragraphs = soup.find_all("p")
for p in paragraphs:
    print(p.text)

# í´ë˜ìŠ¤ë¡œ ì°¾ê¸°
contents = soup.find_all("p", class_="content")

# IDë¡œ ì°¾ê¸°
element = soup.find(id="my-id")

# ì†ì„±ìœ¼ë¡œ ì°¾ê¸°
link = soup.find("a", href="https://example.com")</code></pre>
    <h3>3.3 CSS ì„ íƒì ì‚¬ìš©</h3>
    <pre><code class="language-python">from bs4 import BeautifulSoup

soup = BeautifulSoup(html, "html.parser")

# CSS ì„ íƒìë¡œ ì°¾ê¸°
title = soup.select_one("h1")
paragraphs = soup.select("p.content")
link = soup.select_one("a[href='https://example.com']")

# ì¤‘ì²© ì„ íƒ
items = soup.select("div.container &gt; ul &gt; li")</code></pre>
    <h3>3.4 ë°ì´í„° ì¶”ì¶œ</h3>
    <pre><code class="language-python">from bs4 import BeautifulSoup

soup = BeautifulSoup(html, "html.parser")

# í…ìŠ¤íŠ¸ ì¶”ì¶œ
text = soup.find("p").text
text = soup.find("p").get_text()

# ì†ì„± ì¶”ì¶œ
link = soup.find("a")
href = link["href"]
href = link.get("href")

# HTML ì¶”ì¶œ
html_content = soup.find("div").prettify()</code></pre>
    <h3>3.5 ì‹¤ì „ ì˜ˆì œ: ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìˆ˜ì§‘</h3>
    <pre><code class="language-python">import requests
from bs4 import BeautifulSoup

def get_news_headlines(url):
    """ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìˆ˜ì§‘"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }
    
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "html.parser")
    
    headlines = []
    # ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”
    for article in soup.find_all("h2", class_="headline"):
        title = article.text.strip()
        link = article.find("a")["href"] if article.find("a") else ""
        headlines.append({"title": title, "link": link})
    
    return headlines

# ì‚¬ìš© ì˜ˆì‹œ
# headlines = get_news_headlines("https://news.example.com")
# for headline in headlines:
#     print(headline["title"])</code></pre>
    <hr>
    <h2>4. Seleniumìœ¼ë¡œ ë™ì  ì›¹í˜ì´ì§€ ì²˜ë¦¬</h2>
    <h3>4.1 Selenium ì„¤ì •</h3>
    <pre><code class="language-python">from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# Chrome ë“œë¼ì´ë²„ ì„¤ì •
options = webdriver.ChromeOptions()
options.add_argument("--headless")  # ë¸Œë¼ìš°ì € ì°½ ìˆ¨ê¸°ê¸°
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")

driver = webdriver.Chrome(options=options)</code></pre>
    <h3>4.2 í˜ì´ì§€ ë¡œë“œ ë° ìš”ì†Œ ì°¾ê¸°</h3>
    <pre><code class="language-python">from selenium import webdriver
from selenium.webdriver.common.by import By

driver = webdriver.Chrome()

# í˜ì´ì§€ ì—´ê¸°
driver.get("https://www.example.com")

# ìš”ì†Œ ì°¾ê¸°
element = driver.find_element(By.ID, "my-id")
element = driver.find_element(By.CLASS_NAME, "my-class")
element = driver.find_element(By.CSS_SELECTOR, "div.content")

# ì—¬ëŸ¬ ìš”ì†Œ ì°¾ê¸°
elements = driver.find_elements(By.TAG_NAME, "p")

# í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
text = element.text

# ì†ì„± ê°€ì ¸ì˜¤ê¸°
href = element.get_attribute("href")

driver.quit()</code></pre>
    <h3>4.3 ëŒ€ê¸° ì²˜ë¦¬</h3>
    <pre><code class="language-python">from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# ëª…ì‹œì  ëŒ€ê¸°
wait = WebDriverWait(driver, 10)
element = wait.until(EC.presence_of_element_located((By.ID, "my-id")))

# ì•”ì‹œì  ëŒ€ê¸°
driver.implicitly_wait(10)

# ì‹œê°„ ëŒ€ê¸°
import time
time.sleep(2)</code></pre>
    <h3>4.4 ë™ì  ì½˜í…ì¸  ì²˜ë¦¬</h3>
    <pre><code class="language-python">from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys

driver = webdriver.Chrome()
driver.get("https://www.example.com")

# ìŠ¤í¬ë¡¤
driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

# í´ë¦­
button = driver.find_element(By.ID, "load-more")
button.click()

# ì…ë ¥
search_box = driver.find_element(By.NAME, "q")
search_box.send_keys("python")
search_box.send_keys(Keys.RETURN)

driver.quit()</code></pre>
    <hr>
    <h2>5. ë°ì´í„° ì €ì¥</h2>
    <h3>5.1 CSV íŒŒì¼ë¡œ ì €ì¥</h3>
    <pre><code class="language-python">import pandas as pd

# ë°ì´í„° ì¤€ë¹„
data = [
    {"ì´ë¦„": "í™ê¸¸ë™", "ë‚˜ì´": 25, "ë„ì‹œ": "ì„œìš¸"},
    {"ì´ë¦„": "ì´ì˜í¬", "ë‚˜ì´": 23, "ë„ì‹œ": "ë¶€ì‚°"},
    {"ì´ë¦„": "ê¹€ì² ìˆ˜", "ë‚˜ì´": 27, "ë„ì‹œ": "ëŒ€êµ¬"}
]

# DataFrame ìƒì„±
df = pd.DataFrame(data)

# CSVë¡œ ì €ì¥
df.to_csv("data.csv", index=False, encoding="utf-8-sig")

# CSV ì½ê¸°
df = pd.read_csv("data.csv", encoding="utf-8-sig")
print(df)</code></pre>
    <h3>5.2 JSON íŒŒì¼ë¡œ ì €ì¥</h3>
    <pre><code class="language-python">import json

# ë°ì´í„° ì¤€ë¹„
data = [
    {"ì´ë¦„": "í™ê¸¸ë™", "ë‚˜ì´": 25},
    {"ì´ë¦„": "ì´ì˜í¬", "ë‚˜ì´": 23}
]

# JSONìœ¼ë¡œ ì €ì¥
with open("data.json", "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

# JSON ì½ê¸°
with open("data.json", "r", encoding="utf-8") as f:
    data = json.load(f)</code></pre>
    <h3>5.3 Excel íŒŒì¼ë¡œ ì €ì¥</h3>
    <pre><code class="language-python">import pandas as pd

df = pd.DataFrame(data)

# Excelë¡œ ì €ì¥
df.to_excel("data.xlsx", index=False, engine="openpyxl")

# Excel ì½ê¸°
df = pd.read_excel("data.xlsx", engine="openpyxl")</code></pre>
    <hr>
    <h2>6. ì‹¤ì „ ì˜ˆì œ</h2>
    <h3>ì˜ˆì œ 1: ê°„ë‹¨í•œ ì›¹ ìŠ¤í¬ë˜í¼</h3>
    <pre><code class="language-python">import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

def scrape_website(url):
    """ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }
    
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "html.parser")
    
    data = []
    # ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
    items = soup.find_all("div", class_="item")
    
    for item in items:
        title = item.find("h3").text.strip() if item.find("h3") else ""
        price = item.find("span", class_="price").text.strip() if item.find("span", class_="price") else ""
        data.append({"ì œëª©": title, "ê°€ê²©": price})
    
    return data

# ì‚¬ìš©
# url = "https://www.example.com/products"
# data = scrape_website(url)
# df = pd.DataFrame(data)
# df.to_csv("products.csv", index=False, encoding="utf-8-sig")</code></pre>
    <h3>ì˜ˆì œ 2: ì—¬ëŸ¬ í˜ì´ì§€ ìˆ˜ì§‘</h3>
    <pre><code class="language-python">import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

def scrape_multiple_pages(base_url, max_pages=5):
    """ì—¬ëŸ¬ í˜ì´ì§€ì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
    all_data = []
    
    for page in range(1, max_pages + 1):
        url = f"{base_url}?page={page}"
        print(f"í˜ì´ì§€ {page} ìˆ˜ì§‘ ì¤‘...")
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.text, "html.parser")
        
        # ë°ì´í„° ì¶”ì¶œ (ì‹¤ì œ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
        items = soup.find_all("div", class_="item")
        for item in items:
            # ë°ì´í„° ì¶”ì¶œ ë¡œì§
            all_data.append({})  # ì‹¤ì œ ë°ì´í„°ë¡œ êµì²´
        
        # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
        time.sleep(1)
    
    return all_data

# ì‚¬ìš©
# data = scrape_multiple_pages("https://www.example.com/list", max_pages=10)
# df = pd.DataFrame(data)
# df.to_csv("all_data.csv", index=False, encoding="utf-8-sig")</code></pre>
    <h3>ì˜ˆì œ 3: ë™ì  ì›¹í˜ì´ì§€ ìŠ¤í¬ë˜í•‘</h3>
    <pre><code class="language-python">from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time

def scrape_dynamic_page(url):
    """ë™ì  ì›¹í˜ì´ì§€ì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    
    driver = webdriver.Chrome(options=options)
    driver.get(url)
    
    # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
    wait = WebDriverWait(driver, 10)
    wait.until(EC.presence_of_element_located((By.CLASS_NAME, "content")))
    
    data = []
    
    # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ (í•„ìš”í•œ ê²½ìš°)
    try:
        while True:
            more_button = driver.find_element(By.ID, "load-more")
            if more_button.is_displayed():
                more_button.click()
                time.sleep(2)
            else:
                break
    except:
        pass
    
    # ë°ì´í„° ì¶”ì¶œ
    items = driver.find_elements(By.CLASS_NAME, "item")
    for item in items:
        title = item.find_element(By.TAG_NAME, "h3").text
        # ì¶”ê°€ ë°ì´í„° ì¶”ì¶œ
        data.append({"ì œëª©": title})
    
    driver.quit()
    return data

# ì‚¬ìš©
# data = scrape_dynamic_page("https://www.example.com")
# df = pd.DataFrame(data)
# df.to_csv("dynamic_data.csv", index=False, encoding="utf-8-sig")</code></pre>
    <hr>
    <h2>7. ì£¼ì˜ì‚¬í•­ê³¼ ëª¨ë²” ì‚¬ë¡€</h2>
    <h3>7.1 ë²•ì  ë° ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­</h3>
    <pre><code class="language-python"># 1. robots.txt í™•ì¸
import urllib.robotparser

rp = urllib.robotparser.RobotFileParser()
rp.set_url("https://www.example.com/robots.txt")
rp.read()

if rp.can_fetch("*", "https://www.example.com/page"):
    # ìŠ¤í¬ë˜í•‘ ê°€ëŠ¥
    pass
else:
    # ìŠ¤í¬ë˜í•‘ ë¶ˆê°€
    print("ìŠ¤í¬ë˜í•‘ì´ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")</code></pre>
    <h3>7.2 ì„œë²„ ë¶€í•˜ ë°©ì§€</h3>
    <pre><code class="language-python">import time
import random

# ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„
time.sleep(1)  # ê³ ì • ëŒ€ê¸°
time.sleep(random.uniform(1, 3))  # ëœë¤ ëŒ€ê¸°

# ìš”ì²­ ì œí•œ
max_requests = 100
request_count = 0

for url in urls:
    if request_count &gt;= max_requests:
        break
    # ìš”ì²­ ì²˜ë¦¬
    request_count += 1
    time.sleep(1)</code></pre>
    <h3>7.3 ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„</h3>
    <pre><code class="language-python">import requests
import time

def fetch_with_retry(url, max_retries=3):
    """ì¬ì‹œë„ ë¡œì§ì´ ìˆëŠ” ìš”ì²­"""
    for attempt in range(max_retries):
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            if attempt &lt; max_retries - 1:
                wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„
                print(f"ì¬ì‹œë„ {attempt + 1}/{max_retries} ({wait_time}ì´ˆ ëŒ€ê¸°)")
                time.sleep(wait_time)
            else:
                print(f"ìš”ì²­ ì‹¤íŒ¨: {e}")
                return None
    return None</code></pre>
    <h3>7.4 ëª¨ë²” ì‚¬ë¡€ ì²´í¬ë¦¬ìŠ¤íŠ¸</h3>
    <ul>
    <li>âœ… robots.txt í™•ì¸</li>
    <li>âœ… User-Agent ì„¤ì •</li>
    <li>âœ… ì ì ˆí•œ ëŒ€ê¸° ì‹œê°„ ì„¤ì •</li>
    <li>âœ… ì—ëŸ¬ ì²˜ë¦¬ êµ¬í˜„</li>
    <li>âœ… ë°ì´í„° ê²€ì¦</li>
    <li>âœ… ìš”ì²­ ì œí•œ ì„¤ì •</li>
    <li>âœ… ì´ìš©ì•½ê´€ ì¤€ìˆ˜</li>
    </ul>
    <hr>
    <div class="summary">
    <h2>8. ìš”ì•½</h2>
    <h3>í•µì‹¬ ì •ë¦¬</h3>
    <ol>
    <li><strong>requests</strong>: HTTP ìš”ì²­ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬</li>
    <li><strong>BeautifulSoup</strong>: HTML íŒŒì‹± ë° ë°ì´í„° ì¶”ì¶œ</li>
    <li><strong>Selenium</strong>: ë™ì  ì›¹í˜ì´ì§€ ì²˜ë¦¬</li>
    <li><strong>ë°ì´í„° ì €ì¥</strong>: CSV, JSON, Excel í˜•ì‹ìœ¼ë¡œ ì €ì¥</li>
    <li><strong>ì—ëŸ¬ ì²˜ë¦¬</strong>: ì¬ì‹œë„ ë¡œì§ ë° ì˜ˆì™¸ ì²˜ë¦¬</li>
    <li><strong>ìœ¤ë¦¬ì  ìŠ¤í¬ë˜í•‘</strong>: robots.txt í™•ì¸, ì„œë²„ ë¶€í•˜ ë°©ì§€</li>
    </ol>
    <h3>AICE ì‹¤ì „ íŒ</h3>
    <ul>
    <li><strong>ì„ íƒì</strong>: CSS ì„ íƒìì™€ find ë©”ì„œë“œ ì¡°í•© í™œìš©</li>
    <li><strong>ëŒ€ê¸° ì‹œê°„</strong>: ë™ì  ì½˜í…ì¸ ëŠ” ì¶©ë¶„í•œ ëŒ€ê¸° ì‹œê°„ í•„ìš”</li>
    <li><strong>ë°ì´í„° ê²€ì¦</strong>: ìˆ˜ì§‘í•œ ë°ì´í„°ì˜ ìœ íš¨ì„± í™•ì¸</li>
    <li><strong>ì½”ë“œ ì¬ì‚¬ìš©</strong>: í•¨ìˆ˜ë¡œ ëª¨ë“ˆí™”í•˜ì—¬ ì¬ì‚¬ìš©ì„± í–¥ìƒ</li>
    </ul>
    <div class="tip"><strong>ğŸ’¡ Tip: ì›¹ ìŠ¤í¬ë˜í•‘ì€ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ì— ë¯¼ê°í•©ë‹ˆë‹¤. ì •ê¸°ì ìœ¼ë¡œ ì½”ë“œë¥¼ ì ê²€í•˜ê³  ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.</strong></div>
    </div>
    <hr>
    <div class="checklist">
    <h2>âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸</h2>
    <div class="checklist-item"><input type="checkbox" ><label>requestsë¡œ HTTP ìš”ì²­ ë³´ë‚´ê¸°</label></div>
    <div class="checklist-item"><input type="checkbox" ><label>BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±</label></div>
    <div class="checklist-item"><input type="checkbox" ><label>CSS ì„ íƒìë¡œ ìš”ì†Œ ì°¾ê¸°</label></div>
    <div class="checklist-item"><input type="checkbox" ><label>Seleniumìœ¼ë¡œ ë™ì  ì›¹í˜ì´ì§€ ì²˜ë¦¬</label></div>
    <div class="checklist-item"><input type="checkbox" ><label>ë°ì´í„°ë¥¼ CSV/JSONìœ¼ë¡œ ì €ì¥</label></div>
    <div class="checklist-item"><input type="checkbox" ><label>ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ êµ¬í˜„</label></div>
    <div class="checklist-item"><input type="checkbox" ><label>robots.txt í™•ì¸ ë° ìœ¤ë¦¬ì  ìŠ¤í¬ë˜í•‘</label></div>
    <div class="checklist-item"><input type="checkbox" ><label>ì‹¤ìŠµ ì½”ë“œ ì‘ì„± ë° ì‹¤í–‰ ì™„ë£Œ</label></div>
    </div>
    <hr>
    <h2>ğŸ“š ì°¸ê³  ìë£Œ</h2>
    <ul>
    <li><a href="https://requests.readthedocs.io/">requests ê³µì‹ ë¬¸ì„œ</a></li>
    <li><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup ê³µì‹ ë¬¸ì„œ</a></li>
    <li><a href="https://www.selenium.dev/documentation/">Selenium ê³µì‹ ë¬¸ì„œ</a></li>
    <li><a href="https://pandas.pydata.org/docs/">Pandas ê³µì‹ ë¬¸ì„œ</a></li>
    </ul>
    <hr>
    <p><strong>ì‘ì„±ì¼</strong>: 2025-11-18  </p>
    <p><strong>ë‹¤ìŒ í•™ìŠµ</strong>: 03_ë°ì´í„°ë¶„ì„</p>
    </div>
    
    <div class="footer">
      <p>AICE Associate ì‹œí—˜ ëŒ€ë¹„ | í•™ìŠµ ìë£Œ</p>
    </div>
  </div>
</body>
</html>

