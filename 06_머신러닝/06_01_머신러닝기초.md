# 06-01. ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ

## ğŸ“‹ ëª©ì°¨

- [1. ë¨¸ì‹ ëŸ¬ë‹ì´ë€?](#1-ë¨¸ì‹ ëŸ¬ë‹ì´ë€)
- [2. ì§€ë„í•™ìŠµ vs ë¹„ì§€ë„í•™ìŠµ](#2-ì§€ë„í•™ìŠµ-vs-ë¹„ì§€ë„í•™ìŠµ)
- [3. Scikit-learn ê¸°ì´ˆ](#3-scikit-learn-ê¸°ì´ˆ)
- [4. íšŒê·€ ëª¨ë¸](#4-íšŒê·€-ëª¨ë¸)
- [5. ë¶„ë¥˜ ëª¨ë¸](#5-ë¶„ë¥˜-ëª¨ë¸)
- [6. ëª¨ë¸ í‰ê°€](#6-ëª¨ë¸-í‰ê°€)
- [7. ì‹¤ìŠµ](#7-ì‹¤ìŠµ)
- [8. ìš”ì•½](#8-ìš”ì•½)

---

## 1. ë¨¸ì‹ ëŸ¬ë‹ì´ë€?

**ë¨¸ì‹ ëŸ¬ë‹**ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ì´ë‚˜ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.

### 1.1 ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¢…ë¥˜

- **ì§€ë„í•™ìŠµ**: ì •ë‹µ(ë ˆì´ë¸”)ì´ ìˆëŠ” ë°ì´í„°ë¡œ í•™ìŠµ
- **ë¹„ì§€ë„í•™ìŠµ**: ì •ë‹µ ì—†ì´ ë°ì´í„°ì˜ íŒ¨í„´ ë°œê²¬
- **ê°•í™”í•™ìŠµ**: í™˜ê²½ê³¼ ìƒí˜¸ì‘ìš©í•˜ë©° í•™ìŠµ

---

## 2. ì§€ë„í•™ìŠµ vs ë¹„ì§€ë„í•™ìŠµ

### 2.1 ì§€ë„í•™ìŠµ

```python
# íšŒê·€: ì—°ì†ì ì¸ ê°’ ì˜ˆì¸¡ (ì˜ˆ: ì§‘ ê°€ê²©, ì˜¨ë„)
# ë¶„ë¥˜: ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡ (ì˜ˆ: ìŠ¤íŒ¸/ì •ìƒ, ê³ ì–‘ì´/ê°•ì•„ì§€)
```

### 2.2 ë¹„ì§€ë„í•™ìŠµ

```python
# í´ëŸ¬ìŠ¤í„°ë§: ë¹„ìŠ·í•œ ë°ì´í„° ê·¸ë£¹í™”
# ì°¨ì› ì¶•ì†Œ: ë°ì´í„°ì˜ ì°¨ì› ê°ì†Œ
```

---

## 3. Scikit-learn ê¸°ì´ˆ

### 3.1 ê¸°ë³¸ êµ¬ì¡°

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# 1. ë°ì´í„° ì¤€ë¹„
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# 2. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LinearRegression()
model.fit(X_train, y_train)

# 3. ì˜ˆì¸¡
y_pred = model.predict(X_test)

# 4. í‰ê°€
mse = mean_squared_error(y_test, y_pred)
```

---

## 4. íšŒê·€ ëª¨ë¸

### 4.1 ì„ í˜• íšŒê·€

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LinearRegression()
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)

# í‰ê°€
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
```

### 4.2 ë‹¤í•­ íšŒê·€

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# ë‹¤í•­ íŠ¹ì„± ìƒì„±
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X_train)

# ëª¨ë¸ í•™ìŠµ
model = LinearRegression()
model.fit(X_poly, y_train)
```

---

## 5. ë¶„ë¥˜ ëª¨ë¸

### 5.1 ë¡œì§€ìŠ¤í‹± íšŒê·€

```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LogisticRegression()
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)

# í‰ê°€
accuracy = accuracy_score(y_test, y_pred)
print(classification_report(y_test, y_pred))
```

### 5.2 ê²°ì • íŠ¸ë¦¬

```python
from sklearn.tree import DecisionTreeClassifier

# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = DecisionTreeClassifier(max_depth=5)
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)
```

### 5.3 ëœë¤ í¬ë ˆìŠ¤íŠ¸

```python
from sklearn.ensemble import RandomForestClassifier

# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)
```

---

## 6. ëª¨ë¸ í‰ê°€

### 6.1 íšŒê·€ í‰ê°€ ì§€í‘œ

```python
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
```

### 6.2 ë¶„ë¥˜ í‰ê°€ ì§€í‘œ

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
```

### 6.3 êµì°¨ ê²€ì¦

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)
print(f"í‰ê·  ì ìˆ˜: {scores.mean():.2f}")
```

---

## 7. ì‹¤ìŠµ

### ì‹¤ìŠµ: ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# ë°ì´í„° ë¡œë“œ
iris = load_iris()
X, y = iris.data, iris.target

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ëª¨ë¸ í•™ìŠµ
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred = model.predict(X_test)

# í‰ê°€
accuracy = accuracy_score(y_test, y_pred)
print(f"ì •í™•ë„: {accuracy:.2f}")
print(classification_report(y_test, y_pred))
```

---

## 8. ìš”ì•½

### í•µì‹¬ ì •ë¦¬

1. **ì§€ë„í•™ìŠµ**: íšŒê·€(ì—°ì†ê°’), ë¶„ë¥˜(ì¹´í…Œê³ ë¦¬)
2. **Scikit-learn**: fit(), predict() íŒ¨í„´
3. **ëª¨ë¸ í‰ê°€**: MSE, RÂ² (íšŒê·€), Accuracy, F1 (ë¶„ë¥˜)
4. **êµì°¨ ê²€ì¦**: ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦

### AICE ì‹¤ì „ íŒ

- **ë°ì´í„° ë¶„í• **: train_test_splitìœ¼ë¡œ ë¶„í• 
- **ëª¨ë¸ ì„ íƒ**: ë¬¸ì œ ìœ í˜•ì— ë§ëŠ” ëª¨ë¸ ì„ íƒ
- **í‰ê°€ ì§€í‘œ**: ë¬¸ì œì— ë§ëŠ” í‰ê°€ ì§€í‘œ ì‚¬ìš©

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì§€ë„í•™ìŠµê³¼ ë¹„ì§€ë„í•™ìŠµ ì°¨ì´ ì´í•´
- [ ] Scikit-learn ê¸°ë³¸ ì‚¬ìš©ë²• ìˆ™ì§€
- [ ] íšŒê·€ ëª¨ë¸ ì´í•´ ë° êµ¬í˜„
- [ ] ë¶„ë¥˜ ëª¨ë¸ ì´í•´ ë° êµ¬í˜„
- [ ] ëª¨ë¸ í‰ê°€ ë°©ë²• ìˆ™ì§€
- [ ] ì‹¤ìŠµ ì½”ë“œ ì‘ì„± ë° ì‹¤í–‰ ì™„ë£Œ

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Scikit-learn ê³µì‹ ë¬¸ì„œ](https://scikit-learn.org/stable/)
- [Scikit-learn íŠœí† ë¦¬ì–¼](https://scikit-learn.org/stable/user_guide.html)

---

**ì‘ì„±ì¼**: 2025-11-19  
**ì´ì „ í•™ìŠµ**: [05_01_ë°ì´í„°ì‹œê°í™”](../05_ì‹œê°í™”/05_01_ë°ì´í„°ì‹œê°í™”.md)  
**ë‹¤ìŒ í•™ìŠµ**: [07_01_ê¸°ì¶œë¬¸ì œë¶„ì„](../07_ê¸°ì¶œë¬¸ì œ/07_01_ê¸°ì¶œë¬¸ì œë¶„ì„.md)

